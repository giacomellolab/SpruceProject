---
title: "Normalisation, using SCTransform"
author: "Yuvarani Masarapu"
date: "4/9/2021"
output: html_document
---

```{r global-options, include=FALSE}
knitr::opts_chunk$set(fig.path='figs/', fig.width=14, fig.height=10, warning=FALSE, message=FALSE, echo = FALSE)
```

```{r libraries-load, echo=FALSE}
suppressPackageStartupMessages({
  library(STutility)
  library(Seurat)
  library(harmony)
  library(gridExtra)
  library(pals)
  library(akima)
  library(readr)
  library(plotly)
  library(tibble)
  library(raster)
  library(dplyr)
  library(stringr)
  library(magrittr)
  library(ggplot2)
  library(imager)
  library(Matrix)
  library(cowplot)
  require(data.table)
  library(magick)
  library(grid)
  library(SeuratObject)
})
```

## Normalisation of the data and preparation for downstream analysis

1. Apply normalisation at this point to each seurat object from the infoTable list saved from script (1_LoadData_Filtering.Rmd), this gives a list of SCT normalised seurat objects
2. Read the list of SCT normalised seurat objects

Inspiration from https://satijalab.org/seurat/archive/v3.0/integration.html#sctransform

```{r echo=FALSE}
infoTable.counts.sep <- readRDS(file = "~/Documents/23-02-2021_spruce_new/infotable_counts.rds")

#step 1
ST_list <- lapply(infoTable.counts.sep, function(x){
                  SCTransform(x, verbose =F, vars.to.regress                   = c("nFeature_RNA"), return.only.var.genes                   = F)})

saveRDS(ST_list, file = "indv_SCT_filt_list.rds")

#the step below (ST merge) doesn't work until prepSCT() function is used as we see in the later lines of code
#this is because the step merges the objects but not the SCT models that come from normalising each seurat object
#ST_merge <- MergeSTData(ST_list[[1]], ST_list[2:length(ST_list)], merge.data = T)

#step 2
indv_SCT_filt_list <- readRDS("~/Documents/23-02-2021_spruce_new/indv_SCT_filt_list.rds")
```

2. Select features for downstream integration

- make sure to save files at each step, helps not lose data if the objects are too big; helps address the "vector memory exhaust" error if you are running this on your local computer's rstudio

- 25k features chosen from pipeline optimised by Alina for the spruce samples (http://uu.diva-portal.org/smash/get/diva2:1502197/FULLTEXT01.pdf)

- RAM memory is increased to 16GB (using **options(future.globals.maxSize = 8000 * 1024^2)**) because loading the seurat objects until this point consumed 4GB RAM which was the default set earlier.

```{r echo=FALSE}
spruce.features <- SelectIntegrationFeatures(object.list = indv_SCT_filt_list, nfeatures = 25000)

saveRDS(spruce.features, file = "integrationFeatures_16-03-21.rds")

#modifying the maximum size of global variables
options(future.globals.maxSize = 8000 * 1024^2)

indv_SCT_filt_list <- PrepSCTIntegration(object.list = indv_SCT_filt_list, anchor.features = spruce.features, verbose = FALSE)

saveRDS(indv_SCT_filt_list, file = "prepSCTIntegration_16-03-21.rds")
```


3. Merge the seurat objects

OBS! Normalisation with SCTransform sort of scales the data as well, so be very careful when/if you want to perform scaling using ScaleData() step. If the data points (i.e the spots) have a huge variance, as true in this case, scaling isn't required and would only make it worse.

In this case, ScaleData() was tried (commented) but discarded because it increased cluster numbers instead of refining them, spots started clustering in batches again instead of blending. SCTransform and then harmony took care of batch correction just fine.

```{r}
spruce.merged <- MergeSTData(indv_SCT_filt_list[[1]], indv_SCT_filt_list[2:length(indv_SCT_filt_list)], merge.data = TRUE)

saveRDS(spruce.merged, file = "spruce_merged_obj_19-03-2021.rds")

#spruce.merged <- ScaleData(object = spruce.merged, assay = "SCT")
```